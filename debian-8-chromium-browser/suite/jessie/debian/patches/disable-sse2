description: don't set sse2 compiler flags on i386
author: Michael Gilbert <mgilbert@debian.org>
debian-bug: http://bugs.debian.org/750361

--- a/cc/raster/texture_compressor.cc
+++ b/cc/raster/texture_compressor.cc
@@ -8,7 +8,7 @@
 #include "base/memory/ptr_util.h"
 #include "cc/raster/texture_compressor_etc1.h"
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(ARCH_CPU_X86_64)
 #include "base/cpu.h"
 #include "cc/raster/texture_compressor_etc1_sse.h"
 #endif
@@ -18,7 +18,7 @@ namespace cc {
 std::unique_ptr<TextureCompressor> TextureCompressor::Create(Format format) {
   switch (format) {
     case kFormatETC1: {
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(ARCH_CPU_X86_64)
       base::CPU cpu;
       if (cpu.has_sse2()) {
         return base::WrapUnique(new TextureCompressorETC1SSE());
--- a/media/base/sinc_resampler.cc
+++ b/media/base/sinc_resampler.cc
@@ -84,7 +84,7 @@
 #include "base/logging.h"
 #include "build/build_config.h"
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #include <xmmintrin.h>
 #define CONVOLVE_FUNC Convolve_SSE
 #elif defined(ARCH_CPU_ARM_FAMILY) && defined(USE_NEON)
@@ -328,7 +328,7 @@ float SincResampler::Convolve_C(const fl
       kernel_interpolation_factor * sum2);
 }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 float SincResampler::Convolve_SSE(const float* input_ptr, const float* k1,
                                   const float* k2,
                                   double kernel_interpolation_factor) {
--- a/media/base/sinc_resampler.h
+++ b/media/base/sinc_resampler.h
@@ -96,7 +96,7 @@ class MEDIA_EXPORT SincResampler {
   // ARM, NEON support is chosen at compile time based on compilation flags.
   static float Convolve_C(const float* input_ptr, const float* k1,
                           const float* k2, double kernel_interpolation_factor);
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
   static float Convolve_SSE(const float* input_ptr, const float* k1,
                             const float* k2,
                             double kernel_interpolation_factor);
--- a/media/base/sinc_resampler_perftest.cc
+++ b/media/base/sinc_resampler_perftest.cc
@@ -22,7 +22,7 @@ static const double kKernelInterpolation
 static void DoNothing(int frames, float* destination) {}
 
 // Define platform independent function name for Convolve* tests.
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #define CONVOLVE_FUNC Convolve_SSE
 #elif defined(ARCH_CPU_ARM_FAMILY) && defined(USE_NEON)
 #define CONVOLVE_FUNC Convolve_NEON
--- a/media/base/sinc_resampler_unittest.cc
+++ b/media/base/sinc_resampler_unittest.cc
@@ -153,7 +153,7 @@ TEST(SincResamplerTest, DISABLED_SetRati
 
 
 // Define platform independent function name for Convolve* tests.
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #define CONVOLVE_FUNC Convolve_SSE
 #elif defined(ARCH_CPU_ARM_FAMILY) && defined(USE_NEON)
 #define CONVOLVE_FUNC Convolve_NEON
--- a/media/base/vector_math.cc
+++ b/media/base/vector_math.cc
@@ -11,7 +11,7 @@
 #include "build/build_config.h"
 
 // NaCl does not allow intrinsics.
-#if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_NACL)
+#if defined(__x86_64__) && !defined(OS_NACL)
 #include <xmmintrin.h>
 // Don't use custom SSE versions where the auto-vectorized C version performs
 // better, which is anywhere clang is used.
@@ -89,7 +89,7 @@ std::pair<float, float> EWMAAndMaxPower_
   return result;
 }
 
-#if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_NACL)
+#if defined(__x86_64__) && !defined(OS_NACL)
 void FMUL_SSE(const float src[], float scale, int len, float dest[]) {
   const int rem = len % 4;
   const int last_index = len - rem;
--- a/media/base/vector_math_perftest.cc
+++ b/media/base/vector_math_perftest.cc
@@ -83,7 +83,7 @@ class VectorMathPerfTest : public testin
 };
 
 // Define platform dependent function names for SIMD optimized methods.
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #define FMAC_FUNC FMAC_SSE
 #define FMUL_FUNC FMUL_SSE
 #define EWMAAndMaxPower_FUNC EWMAAndMaxPower_SSE
--- a/media/base/vector_math_testing.h
+++ b/media/base/vector_math_testing.h
@@ -19,7 +19,7 @@ MEDIA_EXPORT void FMUL_C(const float src
 MEDIA_EXPORT std::pair<float, float> EWMAAndMaxPower_C(
     float initial_value, const float src[], int len, float smoothing_factor);
 
-#if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_NACL)
+#if defined(__x86_64__) && !defined(OS_NACL)
 MEDIA_EXPORT void FMAC_SSE(const float src[], float scale, int len,
                            float dest[]);
 MEDIA_EXPORT void FMUL_SSE(const float src[], float scale, int len,
--- a/media/base/vector_math_unittest.cc
+++ b/media/base/vector_math_unittest.cc
@@ -76,7 +76,7 @@ TEST_F(VectorMathTest, FMAC) {
     VerifyOutput(kResult);
   }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
   {
     SCOPED_TRACE("FMAC_SSE");
     FillTestVectors(kInputFillValue, kOutputFillValue);
@@ -117,7 +117,7 @@ TEST_F(VectorMathTest, FMUL) {
     VerifyOutput(kResult);
   }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
   {
     SCOPED_TRACE("FMUL_SSE");
     FillTestVectors(kInputFillValue, kOutputFillValue);
@@ -225,7 +225,7 @@ class EWMATestScenario {
       EXPECT_NEAR(expected_max_, result.second, 0.0000001f);
     }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
     {
       SCOPED_TRACE("EWMAAndMaxPower_SSE");
       const std::pair<float, float>& result = vector_math::EWMAAndMaxPower_SSE(
--- a/skia/ext/convolver.h
+++ b/skia/ext/convolver.h
@@ -17,7 +17,6 @@
 // We can build SSE2 optimized versions for all x86 CPUs
 // except when building for the IOS emulator.
 #if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_IOS)
-#define SIMD_SSE2 1
 #define SIMD_PADDING 8  // 8 * int16_t
 #endif
 
--- a/third_party/WebKit/Source/platform/audio/DirectConvolver.cpp
+++ b/third_party/WebKit/Source/platform/audio/DirectConvolver.cpp
@@ -35,7 +35,7 @@
 #include "platform/audio/VectorMath.h"
 #include "wtf/CPU.h"
 
-#if (CPU(X86) || CPU(X86_64)) && !OS(MACOSX)
+#if (CPU(X86_64)) && !OS(MACOSX)
 #include <emmintrin.h>
 #endif
 
@@ -83,7 +83,7 @@ void DirectConvolver::process(AudioFloat
 #endif  // CPU(X86)
 #else
   size_t i = 0;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   // Convolution using SSE2. Currently only do this if both |kernelSize| and
   // |framesToProcess| are multiples of 4. If not, use the straightforward loop
   // below.
@@ -397,7 +397,7 @@ void DirectConvolver::process(AudioFloat
       }
       destP[i++] = sum;
     }
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   }
 #endif
 #endif  // OS(MACOSX)
--- a/third_party/WebKit/Source/platform/audio/SincResampler.cpp
+++ b/third_party/WebKit/Source/platform/audio/SincResampler.cpp
@@ -31,7 +31,7 @@
 #include "wtf/CPU.h"
 #include "wtf/MathExtras.h"
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 #include <emmintrin.h>
 #endif
 
@@ -269,7 +269,7 @@ void SincResampler::process(AudioSourceP
       {
         float input;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
         // If the sourceP address is not 16-byte aligned, the first several
         // frames (at most three) should be processed seperately.
         while ((reinterpret_cast<uintptr_t>(inputP) & 0x0F) && n) {
--- a/third_party/WebKit/Source/platform/audio/VectorMath.cpp
+++ b/third_party/WebKit/Source/platform/audio/VectorMath.cpp
@@ -33,7 +33,7 @@
 #include <Accelerate/Accelerate.h>
 #endif
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 #include <emmintrin.h>
 #endif
 
@@ -173,7 +173,7 @@ void vsma(const float* sourceP,
           size_t framesToProcess) {
   int n = framesToProcess;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((sourceStride == 1) && (destStride == 1)) {
     float k = *scale;
 
@@ -271,7 +271,7 @@ void vsmul(const float* sourceP,
            size_t framesToProcess) {
   int n = framesToProcess;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((sourceStride == 1) && (destStride == 1)) {
     float k = *scale;
 
@@ -360,7 +360,7 @@ void vsmul(const float* sourceP,
       sourceP += sourceStride;
       destP += destStride;
     }
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   }
 #endif
 }
@@ -374,7 +374,7 @@ void vadd(const float* source1P,
           size_t framesToProcess) {
   int n = framesToProcess;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((sourceStride1 == 1) && (sourceStride2 == 1) && (destStride == 1)) {
     // If the sourceP address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
@@ -501,7 +501,7 @@ void vadd(const float* source1P,
       source2P += sourceStride2;
       destP += destStride;
     }
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   }
 #endif
 }
@@ -515,7 +515,7 @@ void vmul(const float* source1P,
           size_t framesToProcess) {
   int n = framesToProcess;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((sourceStride1 == 1) && (sourceStride2 == 1) && (destStride == 1)) {
     // If the source1P address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
@@ -615,7 +615,7 @@ void zvmul(const float* real1P,
            float* imagDestP,
            size_t framesToProcess) {
   unsigned i = 0;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   // Only use the SSE optimization in the very common case that all addresses
   // are 16-byte aligned.  Otherwise, fall through to the scalar code below.
   if (!(reinterpret_cast<uintptr_t>(real1P) & 0x0F) &&
@@ -674,7 +674,7 @@ void vsvesq(const float* sourceP,
   int n = framesToProcess;
   float sum = 0;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (sourceStride == 1) {
     // If the sourceP address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
@@ -743,7 +743,7 @@ void vmaxmgv(const float* sourceP,
   int n = framesToProcess;
   float max = 0;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (sourceStride == 1) {
     // If the sourceP address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
--- a/third_party/WebKit/Source/platform/graphics/cpu/x86/WebGLImageConversionSSE.h
+++ b/third_party/WebKit/Source/platform/graphics/cpu/x86/WebGLImageConversionSSE.h
@@ -5,7 +5,7 @@
 #ifndef WebGLImageConversionSSE_h
 #define WebGLImageConversionSSE_h
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 
 #include <emmintrin.h>
 
--- a/third_party/WebKit/Source/platform/graphics/gpu/WebGLImageConversion.cpp
+++ b/third_party/WebKit/Source/platform/graphics/gpu/WebGLImageConversion.cpp
@@ -441,7 +441,7 @@ void unpack<WebGLImageConversion::DataFo
   const uint32_t* source32 = reinterpret_cast_ptr<const uint32_t*>(source);
   uint32_t* destination32 = reinterpret_cast_ptr<uint32_t*>(destination);
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::unpackOneRowOfBGRA8LittleToRGBA8(source32, destination32, pixelsPerRow);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
@@ -467,7 +467,7 @@ void unpack<WebGLImageConversion::DataFo
     const uint16_t* source,
     uint8_t* destination,
     unsigned pixelsPerRow) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::unpackOneRowOfRGBA5551LittleToRGBA8(source, destination, pixelsPerRow);
 #endif
 #if HAVE(ARM_NEON_INTRINSICS)
@@ -496,7 +496,7 @@ void unpack<WebGLImageConversion::DataFo
     const uint16_t* source,
     uint8_t* destination,
     unsigned pixelsPerRow) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::unpackOneRowOfRGBA4444LittleToRGBA8(source, destination, pixelsPerRow);
 #endif
 #if HAVE(ARM_NEON_INTRINSICS)
@@ -711,7 +711,7 @@ void pack<WebGLImageConversion::DataForm
           uint8_t>(const uint8_t* source,
                    uint8_t* destination,
                    unsigned pixelsPerRow) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::packOneRowOfRGBA8LittleToR8(source, destination, pixelsPerRow);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
@@ -768,7 +768,7 @@ void pack<WebGLImageConversion::DataForm
           uint8_t>(const uint8_t* source,
                    uint8_t* destination,
                    unsigned pixelsPerRow) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::packOneRowOfRGBA8LittleToRA8(source, destination, pixelsPerRow);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
@@ -880,7 +880,7 @@ void pack<WebGLImageConversion::DataForm
           uint8_t>(const uint8_t* source,
                    uint8_t* destination,
                    unsigned pixelsPerRow) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::packOneRowOfRGBA8LittleToRGBA8(source, destination, pixelsPerRow);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
--- a/third_party/WebKit/Source/modules/webaudio/AudioParamTimeline.cpp
+++ b/third_party/WebKit/Source/modules/webaudio/AudioParamTimeline.cpp
@@ -32,7 +32,7 @@
 #include "wtf/PtrUtil.h"
 #include <algorithm>
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 #include <emmintrin.h>
 #endif
 
@@ -1269,7 +1269,7 @@ std::tuple<size_t, float, unsigned> Audi
     size_t currentFrame,
     float value,
     unsigned writeIndex) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   auto numberOfValues = currentState.numberOfValues;
 #endif
   auto fillToFrame = currentState.fillToFrame;
@@ -1282,7 +1282,7 @@ std::tuple<size_t, float, unsigned> Audi
   double deltaTime = time2 - time1;
   float k = deltaTime > 0 ? 1 / deltaTime : 0;
   const float valueDelta = value2 - value1;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (fillToFrame > writeIndex) {
     // Minimize in-loop operations. Calculate starting value and increment.
     // Next step: value += inc.
@@ -1409,7 +1409,7 @@ std::tuple<size_t, float, unsigned> Audi
     size_t currentFrame,
     float value,
     unsigned writeIndex) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   auto numberOfValues = currentState.numberOfValues;
 #endif
   auto fillToFrame = currentState.fillToFrame;
@@ -1459,7 +1459,7 @@ std::tuple<size_t, float, unsigned> Audi
     for (; writeIndex < fillToFrame; ++writeIndex)
       values[writeIndex] = target;
   } else {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
     if (fillToFrame > writeIndex) {
       // Resolve recursion by expanding constants to achieve a 4-step
       // loop unrolling.
@@ -1591,7 +1591,7 @@ std::tuple<size_t, float, unsigned> Audi
   // Oversampled curve data can be provided if sharp discontinuities are
   // desired.
   unsigned k = 0;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (fillToFrame > writeIndex) {
     const __m128 vCurveVirtualIndex = _mm_set_ps1(curveVirtualIndex);
     const __m128 vCurvePointsPerFrame = _mm_set_ps1(curvePointsPerFrame);
